{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cfd7c09",
   "metadata": {},
   "source": [
    "## EPA AQS acquisition: NYC regulatory  PM₂.₅ (parameter 88101), November 7–10, 2024\n",
    "\n",
    "This notebook focuses **only on data acquisition** for EPA Air Quality System (AQS) measurements.\n",
    "\n",
    "### What is EPA AQS?\n",
    "\n",
    "EPA AQS is the United States **regulatory air-quality monitoring system**. AQS data come from instruments operated by government agencies and partners using standardized methods and quality assurance. In this lesson’s air-quality data landscape, AQS serves as a **“regulatory reference layer”** that is typically sparser than community sensor networks, but highly documented and widely used.\n",
    "\n",
    "AQS PM₂.₅ data are especially useful for:\n",
    "\n",
    "- Providing an **official reference** for PM₂.₅ conditions during an event window,\n",
    "- Comparing **time patterns** against other sources (alignment and harmonization happen later),\n",
    "- Connecting neighborhood-scale sensing to a **regional/regulatory baseline**.\n",
    "\n",
    "### What this notebook does\n",
    "\n",
    "- Downloads (or reuses) the EPA **AirData pre-generated** hourly PM₂.₅ file for 2024 (`hourly_88101_2024.zip`),\n",
    "- Reads the CSV from the ZIP,\n",
    "- Filters to **New York State** and the **five NYC counties** (Bronx, Kings, New York, Queens, Richmond),\n",
    "- Filters to the event window **Nov 7–10, 2024** (local time),\n",
    "- Writes acquisition outputs to `data/raw/epa/` for later integration.\n",
    "\n",
    "No plotting, resampling, or integrated analysis is performed here. Those steps will happen later in\n",
    "the `m201-air-quality-measures-integrated` notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e85df5c",
   "metadata": {},
   "source": [
    "## Notes on the AirData file\n",
    "\n",
    "This notebook uses EPA’s **AirData** distribution (a downloadable ZIP containing a CSV).\n",
    "\n",
    "- The hourly PM₂.₅ file is large for a full year, so we keep the **ZIP** in `data/raw/epa/` and read the CSV directly from it.\n",
    "- This notebook performs only the minimal filtering needed for the lesson (NYC + event window).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af562090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR: C:\\git\\TOPSTSCHOOL-air-quality\\data\\raw\\epa\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Paths\n",
    "# -------------------------------------------------------------------\n",
    "BASE_DIR = Path(\".\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\" / \"epa\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"RAW_DIR:\", RAW_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d63d906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://aqs.epa.gov/aqsweb/airdata/hourly_88101_2024.zip\n",
      "Saved: C:\\git\\TOPSTSCHOOL-air-quality\\data\\raw\\epa\\hourly_88101_2024.zip\n",
      "Reading hourly_88101_2024.csv from ZIP...\n",
      "EPA raw shape: (8115840, 24)\n",
      "Example columns: ['State Code', 'County Code', 'Site Num', 'Parameter Code', 'POC', 'Latitude', 'Longitude', 'Datum', 'Parameter Name', 'Date Local', 'Time Local', 'Date GMT', 'Time GMT', 'Sample Measurement', 'Units of Measure', 'MDL', 'Uncertainty', 'Qualifier', 'Method Type', 'Method Code']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Download hourly PM2.5 (parameter 88101) for YEAR from EPA AirData (if needed),\n",
    "then read the CSV from the ZIP into a pandas DataFrame.\n",
    "\"\"\"\n",
    "\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Configuration\n",
    "# -------------------------------------------------------------------\n",
    "YEAR = 2024\n",
    "PARAM_CODE = \"88101\"  # PM2.5 FRM/FEM (hourly file code)\n",
    "\n",
    "AIRDATA_ZIP_URL = f\"https://aqs.epa.gov/aqsweb/airdata/hourly_{PARAM_CODE}_{YEAR}.zip\"\n",
    "ZIP_PATH = RAW_DIR / f\"hourly_{PARAM_CODE}_{YEAR}.zip\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Download (if missing)\n",
    "# -------------------------------------------------------------------\n",
    "if ZIP_PATH.exists():\n",
    "    print(f\"ZIP already exists: {ZIP_PATH.name}\")\n",
    "else:\n",
    "    print(f\"Downloading: {AIRDATA_ZIP_URL}\")\n",
    "    resp = requests.get(AIRDATA_ZIP_URL, stream=True, timeout=120)\n",
    "    resp.raise_for_status()\n",
    "    with open(ZIP_PATH, \"wb\") as f:\n",
    "        for chunk in resp.iter_content(chunk_size=1024 * 1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    print(f\"Saved: {ZIP_PATH.resolve()}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Read CSV from ZIP (there should be exactly one CSV inside)\n",
    "# -------------------------------------------------------------------\n",
    "with zipfile.ZipFile(ZIP_PATH, \"r\") as zf:\n",
    "    csv_names = [n for n in zf.namelist() if n.lower().endswith(\".csv\")]\n",
    "    if not csv_names:\n",
    "        raise RuntimeError(\"No CSV file found inside the EPA ZIP.\")\n",
    "    csv_name = csv_names[0]\n",
    "    print(f\"Reading {csv_name} from ZIP...\")\n",
    "\n",
    "    with zf.open(csv_name) as f:\n",
    "        # low_memory=False avoids mixed-type warnings.\n",
    "        df = pd.read_csv(f, low_memory=False)\n",
    "\n",
    "print(\"EPA raw shape:\", df.shape)\n",
    "print(\"Example columns:\", df.columns.tolist()[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589f5bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC subset shape: (51885, 24)\n",
      "NYC counties present: ['005', '047', '081']\n",
      "datetime_local nulls: 0\n",
      "NYC datetime_local min/max: 2024-01-01 00:00:00 2024-12-31 23:00:00\n",
      "NYC event subset shape: (574, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_local</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4885633</th>\n",
       "      <td>2024-11-07 00:00:00</td>\n",
       "      <td>36</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885634</th>\n",
       "      <td>2024-11-07 01:00:00</td>\n",
       "      <td>36</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885635</th>\n",
       "      <td>2024-11-07 02:00:00</td>\n",
       "      <td>36</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885636</th>\n",
       "      <td>2024-11-07 03:00:00</td>\n",
       "      <td>36</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885637</th>\n",
       "      <td>2024-11-07 04:00:00</td>\n",
       "      <td>36</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime_local state_code county_code\n",
       "4885633 2024-11-07 00:00:00         36         005\n",
       "4885634 2024-11-07 01:00:00         36         005\n",
       "4885635 2024-11-07 02:00:00         36         005\n",
       "4885636 2024-11-07 03:00:00         36         005\n",
       "4885637 2024-11-07 04:00:00         36         005"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Normalize column names, filter to NYC, and subset to the event window.\n",
    "\n",
    "We use the AirData columns `date_local` and `time_local` to build a local datetime.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "def _snake(s: str) -> str:\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"_\", s)\n",
    "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "    return s\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) Normalize column names\n",
    "# -------------------------------------------------------------------\n",
    "df.columns = [_snake(c) for c in df.columns]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) Ensure key ID columns are strings with zero-padding\n",
    "# -------------------------------------------------------------------\n",
    "def _zp(series, width):\n",
    "    return series.astype(str).str.strip().str.zfill(width)\n",
    "\n",
    "for col, width in [(\"state_code\", 2), (\"county_code\", 3), (\"site_num\", 4)]:\n",
    "    if col in df.columns:\n",
    "        df[col] = _zp(df[col], width)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) Filter to NYC counties in NY (state FIPS 36)\n",
    "# -------------------------------------------------------------------\n",
    "STATE_NY = \"36\"\n",
    "NYC_COUNTIES = {\n",
    "    \"005\": \"Bronx\",\n",
    "    \"047\": \"Kings\",\n",
    "    \"061\": \"New York\",\n",
    "    \"081\": \"Queens\",\n",
    "    \"085\": \"Richmond\",\n",
    "}\n",
    "\n",
    "if \"state_code\" not in df.columns or \"county_code\" not in df.columns:\n",
    "    raise RuntimeError(\"Expected columns state_code and county_code not found after normalization.\")\n",
    "\n",
    "df_nyc = df[(df[\"state_code\"] == STATE_NY) & (df[\"county_code\"].isin(NYC_COUNTIES.keys()))].copy()\n",
    "print(\"NYC subset shape:\", df_nyc.shape)\n",
    "print(\"NYC counties present:\", sorted(df_nyc[\"county_code\"].unique().tolist()))\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4) Build datetime_local\n",
    "# -------------------------------------------------------------------\n",
    "if \"date_local\" not in df_nyc.columns or \"time_local\" not in df_nyc.columns:\n",
    "    raise RuntimeError(\"Expected date_local/time_local columns not found in AirData file.\")\n",
    "\n",
    "# Make time_local consistently HH:MM (it is often already like '00:00')\n",
    "t = df_nyc[\"time_local\"].astype(str).str.strip()\n",
    "\n",
    "# If time is '0' or '1', treat as hour\n",
    "mask_hour_only = t.str.fullmatch(r\"\\d{1,2}\")\n",
    "t.loc[mask_hour_only] = t.loc[mask_hour_only].str.zfill(2) + \":00\"\n",
    "\n",
    "# If time is 'H:MM', pad hour to 2 digits\n",
    "mask_h_mm = t.str.fullmatch(r\"\\d{1,2}:\\d{2}\")\n",
    "t.loc[mask_h_mm] = t.loc[mask_h_mm].str.replace(r\"^(\\d{1}):\", r\"0\\1:\", regex=True)\n",
    "\n",
    "df_nyc[\"datetime_local\"] = pd.to_datetime(\n",
    "    df_nyc[\"date_local\"].astype(str).str.strip() + \" \" + t,\n",
    "    errors=\"coerce\",\n",
    ")\n",
    "\n",
    "print(\"datetime_local nulls:\", int(df_nyc[\"datetime_local\"].isna().sum()))\n",
    "print(\"NYC datetime_local min/max:\", df_nyc[\"datetime_local\"].min(), df_nyc[\"datetime_local\"].max())\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5) Filter to the event window (local time)\n",
    "# -------------------------------------------------------------------\n",
    "EVENT_START = pd.to_datetime(\"2024-11-07\")\n",
    "EVENT_END   = pd.to_datetime(\"2024-11-11\")  # open interval after 2024-11-10\n",
    "\n",
    "mask = (df_nyc[\"datetime_local\"] >= EVENT_START) & (df_nyc[\"datetime_local\"] < EVENT_END)\n",
    "df_event = df_nyc.loc[mask].copy()\n",
    "\n",
    "print(\"NYC event subset shape:\", df_event.shape)\n",
    "df_event[[\"datetime_local\", \"state_code\", \"county_code\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e036af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified EPA event DataFrame shape: (574, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_local</th>\n",
       "      <th>site_id</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>value</th>\n",
       "      <th>units</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>360050110</td>\n",
       "      <td>36</td>\n",
       "      <td>005</td>\n",
       "      <td>0110</td>\n",
       "      <td>88101</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>4</td>\n",
       "      <td>40.816000</td>\n",
       "      <td>-73.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>360470118</td>\n",
       "      <td>36</td>\n",
       "      <td>047</td>\n",
       "      <td>0118</td>\n",
       "      <td>88101</td>\n",
       "      <td>13.9</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>4</td>\n",
       "      <td>40.694540</td>\n",
       "      <td>-73.927690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>360810124</td>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>0124</td>\n",
       "      <td>88101</td>\n",
       "      <td>13.2</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>4</td>\n",
       "      <td>40.736140</td>\n",
       "      <td>-73.821530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>360050112</td>\n",
       "      <td>36</td>\n",
       "      <td>005</td>\n",
       "      <td>0112</td>\n",
       "      <td>88101</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>4</td>\n",
       "      <td>40.815510</td>\n",
       "      <td>-73.885530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>360810125</td>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>0125</td>\n",
       "      <td>88101</td>\n",
       "      <td>11.6</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>4</td>\n",
       "      <td>40.739264</td>\n",
       "      <td>-73.817694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  datetime_local    site_id state_code county_code site_num  parameter_code  \\\n",
       "0     2024-11-07  360050110         36         005     0110           88101   \n",
       "1     2024-11-07  360470118         36         047     0118           88101   \n",
       "2     2024-11-07  360810124         36         081     0124           88101   \n",
       "3     2024-11-07  360050112         36         005     0112           88101   \n",
       "4     2024-11-07  360810125         36         081     0125           88101   \n",
       "\n",
       "   value                        units  poc   latitude  longitude  \n",
       "0    8.2  Micrograms/cubic meter (LC)    4  40.816000 -73.902000  \n",
       "1   13.9  Micrograms/cubic meter (LC)    4  40.694540 -73.927690  \n",
       "2   13.2  Micrograms/cubic meter (LC)    4  40.736140 -73.821530  \n",
       "3    8.1  Micrograms/cubic meter (LC)    4  40.815510 -73.885530  \n",
       "4   11.6  Micrograms/cubic meter (LC)    4  40.739264 -73.817694  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sites in event window: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_num</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360050110</td>\n",
       "      <td>36</td>\n",
       "      <td>005</td>\n",
       "      <td>0110</td>\n",
       "      <td>40.816000</td>\n",
       "      <td>-73.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360470118</td>\n",
       "      <td>36</td>\n",
       "      <td>047</td>\n",
       "      <td>0118</td>\n",
       "      <td>40.694540</td>\n",
       "      <td>-73.927690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360810124</td>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>0124</td>\n",
       "      <td>40.736140</td>\n",
       "      <td>-73.821530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360050112</td>\n",
       "      <td>36</td>\n",
       "      <td>005</td>\n",
       "      <td>0112</td>\n",
       "      <td>40.815510</td>\n",
       "      <td>-73.885530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360810125</td>\n",
       "      <td>36</td>\n",
       "      <td>081</td>\n",
       "      <td>0125</td>\n",
       "      <td>40.739264</td>\n",
       "      <td>-73.817694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     site_id state_code county_code site_num   latitude  longitude\n",
       "0  360050110         36         005     0110  40.816000 -73.902000\n",
       "1  360470118         36         047     0118  40.694540 -73.927690\n",
       "2  360810124         36         081     0124  40.736140 -73.821530\n",
       "3  360050112         36         005     0112  40.815510 -73.885530\n",
       "4  360810125         36         081     0125  40.739264 -73.817694"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote CSV: C:\\git\\TOPSTSCHOOL-air-quality\\data\\raw\\epa\\epa_pm25_nyc_20241107_10.csv\n",
      "Wrote Parquet: C:\\git\\TOPSTSCHOOL-air-quality\\data\\raw\\epa\\epa_pm25_nyc_20241107_10.parquet\n",
      "Wrote site metadata CSV: C:\\git\\TOPSTSCHOOL-air-quality\\data\\raw\\epa\\NYC_EPA_AQS_sites_eventwindow_20241107_10.csv\n",
      "Wrote site metadata Parquet: C:\\git\\TOPSTSCHOOL-air-quality\\data\\raw\\epa\\NYC_EPA_AQS_sites_eventwindow_20241107_10.parquet\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create a simplified event-window table and write outputs to data/raw/epa/.\n",
    "\n",
    "Outputs:\n",
    "- Site metadata table (unique sites) -> SouthBronxQuantAQDevices style analogue for EPA\n",
    "- Event-window measurements -> epa_pm25_nyc_20241107_10.(parquet|csv)\n",
    "\"\"\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# If df_event is empty, warn and skip writing files\n",
    "# ------------------------------------------------------------------\n",
    "if df_event.empty:\n",
    "    print(\n",
    "        \"WARNING: df_event is empty.\\n\"\n",
    "        \"Check the printed datetime_local min/max above and adjust EVENT_START/EVENT_END\\n\"\n",
    "        \"or use a different year/file for EPA data.\"\n",
    "    )\n",
    "else:\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1) Build a site_id (state + county + site_num)\n",
    "    # ------------------------------------------------------------------\n",
    "    if \"site_num\" not in df_event.columns:\n",
    "        # Some AirData files may use site_number, but hourly files typically use site_num.\n",
    "        # We'll attempt a fallback.\n",
    "        for alt in [\"site_number\", \"site\"]:\n",
    "            if alt in df_event.columns:\n",
    "                df_event[\"site_num\"] = df_event[alt].astype(str).str.zfill(4)\n",
    "                break\n",
    "        if \"site_num\" not in df_event.columns:\n",
    "            raise RuntimeError(\"Could not find a site number column (site_num/site_number/site).\")\n",
    "\n",
    "    df_event[\"site_id\"] = df_event[\"state_code\"] + df_event[\"county_code\"] + df_event[\"site_num\"]\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2) Pick core measurement/value column(s)\n",
    "    # ------------------------------------------------------------------\n",
    "    # Hourly AirData files typically use sample_measurement for the numeric value.\n",
    "    value_col = \"sample_measurement\" if \"sample_measurement\" in df_event.columns else None\n",
    "    if value_col is None:\n",
    "        # fallback: look for any plausible value column\n",
    "        candidates = [c for c in df_event.columns if \"sample\" in c and \"measure\" in c]\n",
    "        if candidates:\n",
    "            value_col = candidates[0]\n",
    "        else:\n",
    "            raise RuntimeError(\"Could not identify the measurement value column (sample_measurement).\")\n",
    "\n",
    "    # Optional columns\n",
    "    unit_col = \"units_of_measure\" if \"units_of_measure\" in df_event.columns else None\n",
    "    poc_col  = \"poc\" if \"poc\" in df_event.columns else None\n",
    "\n",
    "    # Latitude/longitude columns vary slightly; try common options\n",
    "    lat_col = next((c for c in [\"latitude\", \"lat\"] if c in df_event.columns), None)\n",
    "    lon_col = next((c for c in [\"longitude\", \"lon\", \"long\"] if c in df_event.columns), None)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3) Build simplified event table\n",
    "    # ------------------------------------------------------------------\n",
    "    columns_out = {\n",
    "        \"datetime_local\": df_event[\"datetime_local\"],\n",
    "        \"site_id\": df_event[\"site_id\"],\n",
    "        \"state_code\": df_event[\"state_code\"],\n",
    "        \"county_code\": df_event[\"county_code\"],\n",
    "        \"site_num\": df_event[\"site_num\"],\n",
    "        \"parameter_code\": df_event[\"parameter_code\"] if \"parameter_code\" in df_event.columns else PARAM_CODE,\n",
    "        \"value\": df_event[value_col],\n",
    "    }\n",
    "    if unit_col:\n",
    "        columns_out[\"units\"] = df_event[unit_col]\n",
    "    if poc_col:\n",
    "        columns_out[\"poc\"] = df_event[poc_col]\n",
    "    if lat_col:\n",
    "        columns_out[\"latitude\"] = df_event[lat_col]\n",
    "    if lon_col:\n",
    "        columns_out[\"longitude\"] = df_event[lon_col]\n",
    "\n",
    "    df_event_simple = pd.DataFrame(columns_out).sort_values(\"datetime_local\").reset_index(drop=True)\n",
    "\n",
    "    print(\"Simplified EPA event DataFrame shape:\", df_event_simple.shape)\n",
    "    display(df_event_simple.head())\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 4) Site metadata table (unique sites)\n",
    "    # ------------------------------------------------------------------\n",
    "    meta_cols = [\"site_id\", \"state_code\", \"county_code\", \"site_num\"]\n",
    "    if lat_col: meta_cols.append(\"latitude\")\n",
    "    if lon_col: meta_cols.append(\"longitude\")\n",
    "\n",
    "    df_sites = df_event_simple[meta_cols].drop_duplicates().reset_index(drop=True)\n",
    "    print(\"Unique sites in event window:\", df_sites.shape[0])\n",
    "    display(df_sites.head())\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 5) Write outputs to data/raw/epa/\n",
    "    # ------------------------------------------------------------------\n",
    "    out_base = \"epa_pm25_nyc_20241107_10\"\n",
    "    out_csv = RAW_DIR / f\"{out_base}.csv\"\n",
    "    df_event_simple.to_csv(out_csv, index=False)\n",
    "    print(f\"Wrote CSV: {out_csv.resolve()}\")\n",
    "\n",
    "    # Parquet is preferred for the integrated notebook; write if available.\n",
    "    out_parquet = RAW_DIR / f\"{out_base}.parquet\"\n",
    "    try:\n",
    "        df_event_simple.to_parquet(out_parquet, index=False)\n",
    "        print(f\"Wrote Parquet: {out_parquet.resolve()}\")\n",
    "    except Exception as e:\n",
    "        print(\"Parquet write failed (install pyarrow or fastparquet to enable).\")\n",
    "        print(\"Error:\", repr(e))\n",
    "\n",
    "    sites_csv = RAW_DIR / \"NYC_EPA_AQS_sites_eventwindow_20241107_10.csv\"\n",
    "    df_sites.to_csv(sites_csv, index=False)\n",
    "    print(f\"Wrote site metadata CSV: {sites_csv.resolve()}\")\n",
    "\n",
    "    sites_parquet = RAW_DIR / \"NYC_EPA_AQS_sites_eventwindow_20241107_10.parquet\"\n",
    "    try:\n",
    "        df_sites.to_parquet(sites_parquet, index=False)\n",
    "        print(f\"Wrote site metadata Parquet: {sites_parquet.resolve()}\")\n",
    "    except Exception as e:\n",
    "        print(\"Parquet write failed for site metadata.\")\n",
    "        print(\"Error:\", repr(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
